{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7mq7PY-zCAD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3u7Q-gZzG28",
        "outputId": "d3ea2905-e4c0-4e7f-c606-a64acba8a1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUW7B7kHjHtx"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9LOBCsJ6EbK"
      },
      "outputs": [],
      "source": [
        "train_path = \"drive/MyDrive/RNN_data_set/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "test_path = \"drive/MyDrive/RNN_data_set/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
        "valid_path=\"drive/MyDrive/RNN_data_set/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6TYql98z16F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def read_csv(path):\n",
        "  data = pd.read_csv(\n",
        "              path,\n",
        "                sep=\"\\t\",\n",
        "                names=[\"output_lang\", \"input_lang\",\"attestation_count\"],\n",
        "            )\n",
        "  return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0up8EYBLZem"
      },
      "outputs": [],
      "source": [
        "def count_tokens(src_characters,trgt_characters):\n",
        "  encoder_tokens = len(src_characters)\n",
        "  decoder_tokens = len(trgt_characters)\n",
        "  return encoder_tokens,decoder_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3zyGf4bN6cd"
      },
      "outputs": [],
      "source": [
        "def dictionary(src_characters,trgt_characters):\n",
        "  source_token_index={}\n",
        "  target_token_index={}\n",
        "  for i, char in enumerate(src_characters):\n",
        "    source_token_index[char]=i\n",
        "  for i, char in enumerate(trgt_characters):\n",
        "    target_token_index[char]=i\n",
        "  return source_token_index,target_token_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQy7nIo9699d"
      },
      "outputs": [],
      "source": [
        "def data_process(data_path):\n",
        "  source_texts = []\n",
        "  target_texts = []\n",
        "  source_characters = set()\n",
        "  target_characters = set()\n",
        "  with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "  for line in lines[:len(lines) - 1]:\n",
        "    target_text, source_text, _ = line.split(\"\\t\")\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    source_texts.append(source_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in source_text:\n",
        "      source_characters.add(char)\n",
        "    for char in target_text:\n",
        "      target_characters.add(char)\n",
        "    source_characters.add(\" \")\n",
        "    target_characters.add(\" \")\n",
        "  source_characters = sorted(list(source_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "  return source_texts,target_texts,source_characters,target_characters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNttcc8QG0DZ"
      },
      "outputs": [],
      "source": [
        "def encode_decode_data(source_texts,target_texts,encoder_seq_length,\n",
        "                       decoder_seq_length,encoder_tokens,decoder_tokens\n",
        "                            ,source_token_index,target_token_index):\n",
        "\n",
        "  encoder_input_data = np.zeros(\n",
        "      (len(source_texts), encoder_seq_length), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_input_data = np.zeros(\n",
        "      (len(source_texts), decoder_seq_length, decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_target_data = np.zeros(\n",
        "      (len(source_texts), decoder_seq_length, decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "\n",
        "  for i,(x, y) in enumerate(zip(source_texts, target_texts)):\n",
        "    for t, char in enumerate(x):\n",
        "      encoder_input_data[i,t] = source_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = source_token_index[\" \"]\n",
        "    \n",
        "    for t, char in enumerate(y):\n",
        "      decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "      if t > 0:\n",
        "        decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "            \n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "  return encoder_input_data,decoder_input_data,decoder_target_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1lLztxyPnOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f89d0ce-58c5-4332-9f07-d63ad74f0652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "source_texts,target_texts,src_characters,trgt_characters=data_process(train_path)\n",
        "source_token_index,target_token_index=dictionary(src_characters,trgt_characters)\n",
        "encoder_tokens,decoder_tokens=count_tokens(src_characters,trgt_characters)\n",
        "encoder_seq_length = max([len(t) for t in source_texts])\n",
        "decoder_seq_length = max([len(t) for t in target_texts])\n",
        "train_encoder_input_data,train_decoder_input_data,train_decoder_target_data=encode_decode_data(source_texts,target_texts,encoder_seq_length,\n",
        "                                                                                               decoder_seq_length,encoder_tokens,decoder_tokens\n",
        "                                                                                               ,source_token_index,target_token_index)\n",
        "val_source_texts,val_target_texts,val_src_characters,val_trgt_characters=data_process(valid_path)\n",
        "val_encoder_input_data,val_decoder_input_data,val_decoder_target_data=encode_decode_data(val_source_texts,val_target_texts,encoder_seq_length,\n",
        "                                                                                               decoder_seq_length,encoder_tokens,decoder_tokens\n",
        "                                                                                               ,source_token_index,target_token_index)\n",
        "test_source_texts,test_target_texts,test_src_characters,test_trgt_characters=data_process(test_path)\n",
        "test_encoder_input_data,test_decoder_input_data,test_decoder_target_data=encode_decode_data(test_source_texts,test_target_texts,encoder_seq_length,\n",
        "                                                                                               decoder_seq_length,encoder_tokens,decoder_tokens\n",
        "                                                                                               ,source_token_index,target_token_index)\n",
        "\n",
        "print(train_encoder_input_data[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nysIVudviSOG"
      },
      "source": [
        "# make network for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrjPtW9QivQZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model, Sequential,  Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSqj2RaxiQFv"
      },
      "outputs": [],
      "source": [
        "class LSTM_network(object):\n",
        "  def __init__(self,input_embedding,no_encoder_layers,no_decoder_layers,\n",
        "               hidden_layers_size,drop_out,epochs,batch_size,\n",
        "               decoder_tokens,encoder_tokens):\n",
        "    self.input_embedding=input_embedding\n",
        "    self.no_encoder_layers=no_encoder_layers\n",
        "    self.no_decoder_layers=no_decoder_layers\n",
        "    self.hidden_layers_size=hidden_layers_size\n",
        "    self.drop_out=drop_out\n",
        "    self.batch_size=batch_size\n",
        "    self.epochs=epochs\n",
        "    self.encoder_tokens=encoder_tokens\n",
        "    self.decoder_tokens=decoder_tokens\n",
        "    self.initialize(input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens)\n",
        "\n",
        "  def initialize(self,input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens):\n",
        "    encoder_input = keras.Input(shape=(None,))\n",
        "    embedded=tf.keras.layers.Embedding(\n",
        "                input_dim=encoder_tokens,\n",
        "                output_dim=input_embedding)(encoder_input)\n",
        "    encoder_output=embedded\n",
        "    for i in range(0,no_encoder_layers):\n",
        "      encoder = keras.layers.LSTM(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      encoder_output,state_1,state_2= encoder(encoder_output)\n",
        "      encoder_state = [state_1,state_2]\n",
        "    decoder_input = keras.Input(shape=(None, decoder_tokens))\n",
        "    decoder_output=decoder_input\n",
        "    for i in range(no_decoder_layers):\n",
        "      decoder = keras.layers.LSTM(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      decoder_output,_,_= decoder(decoder_output,initial_state=encoder_state)\n",
        "    decoder_dense = keras.layers.Dense(decoder_tokens, activation=\"softmax\")\n",
        "    decoder_output = decoder_dense(decoder_output)\n",
        "    self.model = keras.Model([encoder_input, decoder_input], decoder_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAKING OF RNN NETWORK"
      ],
      "metadata": {
        "id": "C2YargDfoqB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_network(object):\n",
        "  def __init__(self,input_embedding,no_encoder_layers,no_decoder_layers,\n",
        "               hidden_layers_size,drop_out,epochs,batch_size,\n",
        "               decoder_tokens,encoder_tokens):\n",
        "    self.input_embedding=input_embedding\n",
        "    self.no_encoder_layers=no_encoder_layers\n",
        "    self.no_decoder_layers=no_decoder_layers\n",
        "    self.hidden_layers_size=hidden_layers_size\n",
        "    self.drop_out=drop_out\n",
        "    self.batch_size=batch_size\n",
        "    self.epochs=epochs\n",
        "    self.encoder_tokens=encoder_tokens\n",
        "    self.decoder_tokens=decoder_tokens\n",
        "    self.initialize(input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens)\n",
        "\n",
        "  def initialize(self,input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens):\n",
        "    encoder_input = keras.Input(shape=(None,))\n",
        "    embedded=tf.keras.layers.Embedding(\n",
        "    input_dim=encoder_tokens,\n",
        "    output_dim=input_embedding)(encoder_input)\n",
        "    encoder_output=embedded\n",
        "    for i in range(0,no_encoder_layers):\n",
        "      encoder = keras.layers.SimpleRNN(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      encoder_output,state= encoder(encoder_output)\n",
        "      encoder_state = [state]\n",
        "    decoder_input = keras.Input(shape=(None, decoder_tokens))\n",
        "    decoder_output=decoder_input\n",
        "    for i in range(no_decoder_layers):\n",
        "      decoder = keras.layers.SimpleRNN(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      decoder_output,_= decoder(decoder_output,initial_state=encoder_state)\n",
        "    decoder_dense = keras.layers.Dense(decoder_tokens, activation=\"softmax\")\n",
        "    decoder_output = decoder_dense(decoder_output)\n",
        "    self.model = keras.Model([encoder_input, decoder_input], decoder_output)"
      ],
      "metadata": {
        "id": "mmIxP4-covTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAKING OF GRU NETWORK"
      ],
      "metadata": {
        "id": "5BdHXM5Np6gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_network(object):\n",
        "  def __init__(self,input_embedding,no_encoder_layers,no_decoder_layers,\n",
        "               hidden_layers_size,drop_out,epochs,batch_size,\n",
        "               decoder_tokens,encoder_tokens):\n",
        "    self.input_embedding=input_embedding\n",
        "    self.no_encoder_layers=no_encoder_layers\n",
        "    self.no_decoder_layers=no_decoder_layers\n",
        "    self.hidden_layers_size=hidden_layers_size\n",
        "    self.drop_out=drop_out\n",
        "    self.batch_size=batch_size\n",
        "    self.epochs=epochs\n",
        "    self.encoder_tokens=encoder_tokens\n",
        "    self.decoder_tokens=decoder_tokens\n",
        "    self.initialize(input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens)\n",
        "\n",
        "  def initialize(self,input_embedding,no_encoder_layers,no_decoder_layers,hidden_layers_size,drop_out,epochs,batch_size,decoder_tokens,encoder_tokens):\n",
        "    encoder_input = keras.Input(shape=(None,))\n",
        "    embedded=tf.keras.layers.Embedding(\n",
        "    input_dim=encoder_tokens,\n",
        "    output_dim=input_embedding)(encoder_input)\n",
        "    encoder_output=embedded\n",
        "    for i in range(0,no_encoder_layers):\n",
        "      encoder = keras.layers.GRU(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      encoder_output,state= encoder(encoder_output)\n",
        "      encoder_state = [state]\n",
        "    decoder_input = keras.Input(shape=(None, decoder_tokens))\n",
        "    decoder_output=decoder_input\n",
        "    for i in range(no_decoder_layers):\n",
        "      decoder = keras.layers.GRU(\n",
        "                    hidden_layers_size,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=drop_out,\n",
        "                )\n",
        "      decoder_output,_= decoder(decoder_output,initial_state=encoder_state)\n",
        "    decoder_dense = keras.layers.Dense(decoder_tokens, activation=\"softmax\")\n",
        "    decoder_output = decoder_dense(decoder_output)\n",
        "    self.model = keras.Model([encoder_input, decoder_input], decoder_output)"
      ],
      "metadata": {
        "id": "L3BRGqPQp-84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB7beHfFZvUL",
        "outputId": "ac584b01-9906-4573-8139-712c48bdb0ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20,)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    6912        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 256),  525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['lstm[0][0]']                   \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 256),  330752      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 256),  525312      ['lstm_2[0][0]',                 \n",
            "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     16962       ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,930,562\n",
            "Trainable params: 1,930,562\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "691/691 [==============================] - 42s 44ms/step - loss: 1.0195 - accuracy: 0.7341 - val_loss: 0.7043 - val_accuracy: 0.8044\n",
            "141/141 [==============================] - 2s 14ms/step - loss: 0.6910 - accuracy: 0.8079\n"
          ]
        }
      ],
      "source": [
        "model=LSTM_network(256,2,2,256,0.2,5,32,decoder_tokens,encoder_tokens)\n",
        "#image=\"drive/MyDrive/akash.png\"\n",
        "#tf.keras.utils.plot_model(model.model, to_file=image, show_shapes=True)\n",
        "print(train_encoder_input_data[0].shape)\n",
        "print(model.model.summary())\n",
        "model.model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.model.fit([train_encoder_input_data, train_decoder_input_data],\n",
        "    train_decoder_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=1,\n",
        "    validation_data=([val_encoder_input_data, val_decoder_input_data],val_decoder_target_data),\n",
        ")\n",
        "loss,accuracy=model.model.evaluate(x=[test_encoder_input_data, test_decoder_input_data],y=test_decoder_target_data,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opPJvGGc_HMa",
        "outputId": "5a75cf85-e790-4681-e10c-f6a0eb146fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.15)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb \n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb1PXd8Q_VwA",
        "outputId": "5f6e5eff-8bc9-4c60-ad15-1a42e0295fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makashsainics21m003\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_models={\"RNN\":RNN_network,\"LSTM\":LSTM_network,\"GRU\":GRU_network}\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "optimizer={\"rmsprop\":RMSprop,\"adam\":Adam}\n",
        "import numpy as np\n",
        "from wandb.keras import WandbCallback\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop"
      ],
      "metadata": {
        "id": "ktESrYwHEsSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_wandb():\n",
        "    wandb.init(project=\"assignment\", entity=\"cs21m003_cs21d406\")\n",
        "    config = wandb.config\n",
        "    base_model=train_models[config.base_models]\n",
        "    optim=optimizer[config.optimizer]\n",
        "    wandb.run.name=f\"embd_{config.input_embedding}_e_{config.epochs}_bs_{config.batch_size}_enc_layers_{config.no_encoder_layers}_dec_layers_{config.no_decoder_layers}_rate_{config.learning_rate}_drp_{config.drop_out}_hidden_{config.hidden_layers_size}_optim_{config.optimizer}_model_{config.base_models}\"\n",
        "    \"\"\"\n",
        "    params = {\n",
        "    \"input_embedding\":config.input_embedding\n",
        "    \"epochs\"        : config.epochs,\n",
        "    \"batch_size\"    : config.batch_size,\n",
        "    \"no_encoder_layers\"   : config.no_encoder_layers,\n",
        "    \"no_decoder_layers\"    : config.no_decoder_layers,\n",
        "    \"learning_rate\" : config.learning_rate,\n",
        "    \"drop_out\"  : config.drop_out,\n",
        "    \"hidden_layers_size\":config.hidden_layers_size,\n",
        "    \"optimizer\":config.optimizer,\n",
        "    \"base_models\":config.base_models,\n",
        "    }\n",
        "    \"\"\"\n",
        "    model_1=base_model(config.input_embedding,config.no_encoder_layers,config.no_decoder_layers,config.hidden_layers_size,\n",
        "                       config.drop_out,config.epochs,config.batch_size,decoder_tokens,encoder_tokens)\n",
        "    model_1.model.compile(\n",
        "    optimizer=optim(config.learning_rate),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model_1.model.fit([train_encoder_input_data, train_decoder_input_data],\n",
        "    train_decoder_target_data,epochs=config.epochs,batch_size=config.batch_size,validation_data=([val_encoder_input_data, val_decoder_input_data],val_decoder_target_data),\n",
        "          callbacks=[WandbCallback()])\n",
        "    loss,accuracy=model_1.model.evaluate(x=[test_encoder_input_data, test_decoder_input_data],y=test_decoder_target_data,batch_size=config.batch_size)\n",
        "    print(f'test accuracy:{accuracy}')\n",
        "    wandb.log({\"test accuracy\":accuracy})"
      ],
      "metadata": {
        "id": "v2VhjvtbK3Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_hyperparameter_search_using_wandb():\n",
        "    sweep_config = {\n",
        "    \"name\": \"random sweep\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\":{\n",
        "      \"name\": \"ValidationAccuracy\",\n",
        "      \"goal\": \"maximize\"\n",
        "    },\n",
        "    \"parameters\":{\n",
        "      \"input_embedding\": {\"values\": [64,128,256]},\n",
        "      \"epochs\": {\"values\": [5, 10,15]}, \n",
        "      \"batch_size\": {\"values\": [32,64,128]}, \n",
        "      \"no_encoder_layers\": {\"values\": [1, 2,3]}, \n",
        "      \"no_decoder_layers\": {\"values\": [1,2,3]},\n",
        "      \"learning_rate\": {\"values\": [1e-3, 1e-4]}, \n",
        "      \"drop_out\": {\"values\": [0.2,0.3,0.4]},\n",
        "      \"hidden_layers_size\": {\"values\": [64,128,256]},\n",
        "      \"optimizer\": {\"values\": [\"rmsprop\",\"adam\"]},\n",
        "      \"base_models\":{\"values\":[\"RNN\",\"LSTM\",\"GRU\"]}}}\n",
        "  \n",
        "    sweep_id = wandb.sweep(sweep_config, project = \"ASSIGNMENT_3\",entity='cs21m003_cs21d406')\n",
        "    wandb.agent(sweep_id, function=run_wandb,count=30)"
      ],
      "metadata": {
        "id": "w16csj81TMjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "do_hyperparameter_search_using_wandb()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ab63a6aa84de4ef6a225117e952da0b3",
            "acbb004eda864de7be5e02454e2481f1",
            "82278823e6904d65a8d49fc230213839",
            "9f73111fb3e5450792b4d1987f86a996",
            "65495a61f05249b6b36b43486b7dd547",
            "2a2b1d9f24bc41efa609117353bef963",
            "1d20552ac5e24b23b40603fa74b0d560",
            "3cb73ecabd4147b6ae0e7558421f6ea5"
          ]
        },
        "id": "MyHfe6sfYtA6",
        "outputId": "153c4486-cd8b-46b5-ce95-c8299d87de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: auwe7blw\n",
            "Sweep URL: https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/sweeps/auwe7blw\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 64xcxnag with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_models: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_decoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220422_085035-64xcxnag</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/runs/64xcxnag\" target=\"_blank\">mild-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/sweeps/auwe7blw\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/sweeps/auwe7blw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "346/346 [==============================] - 23s 45ms/step - loss: 1.2502 - accuracy: 0.6929 - val_loss: 1.0043 - val_accuracy: 0.7380 - _timestamp: 1650617464.0000 - _runtime: 29.0000\n",
            "Epoch 2/15\n",
            "346/346 [==============================] - 14s 39ms/step - loss: 1.0244 - accuracy: 0.7257 - val_loss: 0.9044 - val_accuracy: 0.7540 - _timestamp: 1650617478.0000 - _runtime: 43.0000\n",
            "Epoch 3/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.9824 - accuracy: 0.7346 - val_loss: 0.8643 - val_accuracy: 0.7637 - _timestamp: 1650617492.0000 - _runtime: 57.0000\n",
            "Epoch 4/15\n",
            "346/346 [==============================] - 14s 39ms/step - loss: 0.9404 - accuracy: 0.7445 - val_loss: 0.8103 - val_accuracy: 0.7742 - _timestamp: 1650617505.0000 - _runtime: 70.0000\n",
            "Epoch 5/15\n",
            "346/346 [==============================] - 14s 39ms/step - loss: 0.8821 - accuracy: 0.7558 - val_loss: 0.7445 - val_accuracy: 0.7875 - _timestamp: 1650617519.0000 - _runtime: 84.0000\n",
            "Epoch 6/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.8299 - accuracy: 0.7659 - val_loss: 0.6935 - val_accuracy: 0.8035 - _timestamp: 1650617533.0000 - _runtime: 98.0000\n",
            "Epoch 7/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.7870 - accuracy: 0.7753 - val_loss: 0.6458 - val_accuracy: 0.8146 - _timestamp: 1650617546.0000 - _runtime: 111.0000\n",
            "Epoch 8/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.7491 - accuracy: 0.7841 - val_loss: 0.6141 - val_accuracy: 0.8210 - _timestamp: 1650617560.0000 - _runtime: 125.0000\n",
            "Epoch 9/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.7209 - accuracy: 0.7907 - val_loss: 0.5920 - val_accuracy: 0.8295 - _timestamp: 1650617574.0000 - _runtime: 139.0000\n",
            "Epoch 10/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6980 - accuracy: 0.7958 - val_loss: 0.5658 - val_accuracy: 0.8345 - _timestamp: 1650617588.0000 - _runtime: 153.0000\n",
            "Epoch 11/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6710 - accuracy: 0.8026 - val_loss: 0.5400 - val_accuracy: 0.8392 - _timestamp: 1650617601.0000 - _runtime: 166.0000\n",
            "Epoch 12/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6462 - accuracy: 0.8087 - val_loss: 0.5098 - val_accuracy: 0.8497 - _timestamp: 1650617615.0000 - _runtime: 180.0000\n",
            "Epoch 13/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6234 - accuracy: 0.8151 - val_loss: 0.4902 - val_accuracy: 0.8546 - _timestamp: 1650617629.0000 - _runtime: 194.0000\n",
            "Epoch 14/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.5972 - accuracy: 0.8221 - val_loss: 0.4645 - val_accuracy: 0.8626 - _timestamp: 1650617643.0000 - _runtime: 208.0000\n",
            "Epoch 15/15\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.5720 - accuracy: 0.8288 - val_loss: 0.4421 - val_accuracy: 0.8689 - _timestamp: 1650617656.0000 - _runtime: 221.0000\n",
            "36/36 [==============================] - 1s 16ms/step - loss: 0.4274 - accuracy: 0.8731\n",
            "test accuracy:0.8731357455253601\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='4.175 MB of 4.175 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab63a6aa84de4ef6a225117e952da0b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▃▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▂▂▃▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.82882</td></tr><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.44212</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.572</td></tr><tr><td>test accuracy</td><td>0.87314</td></tr><tr><td>val_accuracy</td><td>0.86892</td></tr><tr><td>val_loss</td><td>0.44212</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">mild-sweep-1</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/runs/64xcxnag\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/runs/64xcxnag</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220422_085035-64xcxnag/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ec75mbsk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_models: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_decoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220422_085528-ec75mbsk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/runs/ec75mbsk\" target=\"_blank\">major-sweep-2</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/sweeps/auwe7blw\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/ASSIGNMENT_3/sweeps/auwe7blw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 953/1382 [===================>..........] - ETA: 1:25 - loss: 1.3069 - accuracy: 0.6804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1382/1382 [==============================] - 282s 201ms/step - loss: 1.2465 - accuracy: 0.6896 - val_loss: 1.0271 - val_accuracy: 0.7361 - _timestamp: 1650618018.0000 - _runtime: 290.0000\n",
            "Epoch 2/5\n",
            "1382/1382 [==============================] - 276s 200ms/step - loss: 1.0506 - accuracy: 0.7285 - val_loss: 0.8990 - val_accuracy: 0.7698 - _timestamp: 1650618294.0000 - _runtime: 566.0000\n",
            "Epoch 3/5\n",
            "1382/1382 [==============================] - 278s 201ms/step - loss: 0.9495 - accuracy: 0.7528 - val_loss: 0.8027 - val_accuracy: 0.7928 - _timestamp: 1650618572.0000 - _runtime: 844.0000\n",
            "Epoch 4/5\n",
            " 165/1382 [==>...........................] - ETA: 4:02 - loss: 0.9031 - accuracy: 0.7637"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "DL_assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab63a6aa84de4ef6a225117e952da0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acbb004eda864de7be5e02454e2481f1",
              "IPY_MODEL_82278823e6904d65a8d49fc230213839"
            ],
            "layout": "IPY_MODEL_9f73111fb3e5450792b4d1987f86a996"
          }
        },
        "acbb004eda864de7be5e02454e2481f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65495a61f05249b6b36b43486b7dd547",
            "placeholder": "​",
            "style": "IPY_MODEL_2a2b1d9f24bc41efa609117353bef963",
            "value": "4.208 MB of 4.208 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "82278823e6904d65a8d49fc230213839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d20552ac5e24b23b40603fa74b0d560",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cb73ecabd4147b6ae0e7558421f6ea5",
            "value": 1
          }
        },
        "9f73111fb3e5450792b4d1987f86a996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65495a61f05249b6b36b43486b7dd547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2b1d9f24bc41efa609117353bef963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d20552ac5e24b23b40603fa74b0d560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb73ecabd4147b6ae0e7558421f6ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}