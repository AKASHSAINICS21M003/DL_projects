{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ff3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras import  models, optimizers, layers, activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5076437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D ,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f3bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12479306646258732783\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2258055988\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5847212896316704380\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd46403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\deep learning project\\inaturalist_12K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b824eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(256,256,3)\n",
    "output_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae69b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,augmentation=True):\n",
    "    train_path=os.path.join(path,\"train\")\n",
    "    test_path=os.path.join(path,\"val\")\n",
    "    if augmentation==False:\n",
    "        train_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.1)\n",
    "    else:\n",
    "        train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90,\n",
    "                                          zoom_range=0.2,\n",
    "                                          shear_range=0.2,\n",
    "                                          validation_split=0.1,\n",
    "                                          horizontal_flip=True)\n",
    "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    train_data = train_generator.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    valid_data=train_generator.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    test_data=test_generator.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    return train_data,valid_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f3f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0e0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inc_v2(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=InceptionResNetV2(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size,\n",
    "        )\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd98131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inc_v3(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=InceptionV3(include_top=False,\n",
    "            weights=\"imagenet\", \n",
    "            input_shape=input_size,\n",
    "        )\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c12124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xcpt_ion(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=Xception(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size)\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c645fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_net(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=ResNet50(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size)\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101a3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4194336   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 27,782,506\n",
      "Trainable params: 4,194,730\n",
      "Non-trainable params: 23,587,776\n",
      "_________________________________________________________________\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "model=Res_net(image_size,output_size,0.4,True,32)\n",
    "model.model.summary()\n",
    "\n",
    "print(model.model_b.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1678d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models={\"inception_v2\":inc_v2,\"inception_v3\":inc_v3,\"Xception\":Xcpt_ion,\"Resnet_50\":Res_net}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141d4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makashsainics21m003\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519208ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b904e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "np.random.seed(2)\n",
    "class Runner(object):\n",
    "    def __init__(self,inaturalist_data=True,augmentation=True):\n",
    "        if inaturalist_data:\n",
    "            self.initialize_inaturalist_data(augmentation)\n",
    "        else:\n",
    "            self.initialize_data()\n",
    "\n",
    "    def initialize_inaturalist_data(self,augmentation=True):\n",
    "        self.train_data,self.valid_data,self.test_data= get_data(path,augmentation)\n",
    "    \n",
    "\n",
    "    def initialize_data(self):\n",
    "        raise NotImplementedError(\"Please implement this method if you need other dataset.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_activation_function(key):\n",
    "        mapper = {\n",
    "      #\"sigmoid\": Sigmoid,\n",
    "      \"relu\": 'relu'\n",
    "      #\"tanh\": Tanh\n",
    "    }\n",
    "        assert key in mapper\n",
    "        return mapper[key]\n",
    "\n",
    "def run_wandb():\n",
    "    wandb.init(project=\"pretrained_model\", entity=\"cs21m003_cs21d406\")\n",
    "    config = wandb.config\n",
    "    base_model=trained_models[config.models]\n",
    "    wandb.run.name=f\"model_{config.models}_e_{config.epochs}_bs_{config.batch_size}_rate_{config.learning_rate}_aug_{config.augmentation}_BN_{config.batch_normalization}_drp_{config.drop_out}_dense_{config.dense_size}\"\n",
    "    runner=Runner(True,config.augmentation)\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    \"epochs\"        : config.epochs,\n",
    "    \"batch_size\"    : config.batch_size,\n",
    "    \"act_func\"      : config.act_func,\n",
    "    \"learning_rate\" : config.learning_rate,\n",
    "    \"augmentation\"  : config.augmentation,\n",
    "    \"batch_normalization\"  : config.batch_normalization,\n",
    "    \"drop_out\"  : config.drop_out,\n",
    "    \"dense_size\":config.dense_size,\n",
    "    \"models\": config.models\n",
    "\n",
    "    }\n",
    "    \"\"\"\n",
    "    model_1=base_model(image_size,output_size,config.drop_out,config.batch_normalization,config.dense_size)\n",
    "    model_1.model.compile(\n",
    "    optimizer=Adam(config.learning_rate),  # Optimizer\n",
    "    loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
    "    model_1.model.fit(runner.train_data,epochs=config.epochs,batch_size=config.batch_size,validation_data=runner.valid_data,\n",
    "          callbacks=[WandbCallback()])\n",
    "    loss,accuracy=model_1.model.evaluate(runner.test_data,batch_size=config.batch_size)\n",
    "    model_1.model_b.trainable=True\n",
    "    print(model_1.model_b.trainable)\n",
    "    print(f'test accuracy:{accuracy}')\n",
    "    wandb.log({\"test accuracy\":accuracy})\n",
    "\n",
    "def do_hyperparameter_search_using_wandb():\n",
    "    sweep_config = {\n",
    "    \"name\": \"random sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\":{\n",
    "      \"name\": \"ValidationAccuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "      \"epochs\": {\"values\": [5,10]}, \n",
    "      \"batch_size\": {\"values\": [64]}, \n",
    "      #\"act_func\": {\"values\": ['elu', 'relu', 'selu']}, \n",
    "      \"learning_rate\": {\"values\": [1e-3, 1e-4]}, \n",
    "      \"augmentation\": {\"values\": [True,False]} , \n",
    "      \"batch_normalization\": {\"values\": [True,False]},\n",
    "        \n",
    "      \"drop_out\": {\"values\": [0.3,0.4,0.5]},\n",
    "      \"models\": {\"values\": [\"inception_v2\",\"inception_v3\",\"Xception\",\"Resnet_50\"]},\n",
    "      \"dense_size\": {\"values\": [32,64]}}}\n",
    "  \n",
    "    sweep_id = wandb.sweep(sweep_config, project = \"pretrained_model\",entity='cs21m003_cs21d406')\n",
    "    wandb.agent(sweep_id, function=run_wandb,count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5982be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: lxc7l205\n",
      "Sweep URL: https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: giqgwqf3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220329_163536-giqgwqf3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/giqgwqf3\" target=\"_blank\">gentle-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 454s 1s/step - loss: 1.3117 - categorical_accuracy: 0.6552 - val_loss: 0.5788 - val_categorical_accuracy: 0.8132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash saini\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "313/313 [==============================] - 394s 1s/step - loss: 0.8559 - categorical_accuracy: 0.7553 - val_loss: 0.4243 - val_categorical_accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 412s 1s/step - loss: 0.6064 - categorical_accuracy: 0.8184 - val_loss: 0.2897 - val_categorical_accuracy: 0.8998\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 425s 1s/step - loss: 0.4666 - categorical_accuracy: 0.8567 - val_loss: 0.2447 - val_categorical_accuracy: 0.9179\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 419s 1s/step - loss: 0.3479 - categorical_accuracy: 0.8829 - val_loss: 0.1191 - val_categorical_accuracy: 0.9587\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 427s 1s/step - loss: 0.2790 - categorical_accuracy: 0.9060 - val_loss: 0.0704 - val_categorical_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 430s 1s/step - loss: 0.2224 - categorical_accuracy: 0.9268 - val_loss: 0.0612 - val_categorical_accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 422s 1s/step - loss: 0.1791 - categorical_accuracy: 0.9364 - val_loss: 0.0679 - val_categorical_accuracy: 0.9808\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 403s 1s/step - loss: 0.1760 - categorical_accuracy: 0.9408 - val_loss: 0.0335 - val_categorical_accuracy: 0.9891\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 406s 1s/step - loss: 0.1290 - categorical_accuracy: 0.9563 - val_loss: 0.0248 - val_categorical_accuracy: 0.9924\n",
      "63/63 [==============================] - 47s 752ms/step - loss: 1.1526 - categorical_accuracy: 0.7765\n",
      "True\n",
      "test accuracy:0.7764999866485596\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▃▄▅▇▇████</td></tr><tr><td>val_loss</td><td>█▆▄▄▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.02484</td></tr><tr><td>categorical_accuracy</td><td>0.9563</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.12903</td></tr><tr><td>test accuracy</td><td>0.7765</td></tr><tr><td>val_categorical_accuracy</td><td>0.9924</td></tr><tr><td>val_loss</td><td>0.02484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-sweep-1</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/giqgwqf3\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/giqgwqf3</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220329_163536-giqgwqf3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8feinfiv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet_50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220329_174749-8feinfiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8feinfiv\" target=\"_blank\">stoic-sweep-2</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 454s 1s/step - loss: 2.4092 - categorical_accuracy: 0.1603 - val_loss: 2.6146 - val_categorical_accuracy: 0.1509\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 451s 1s/step - loss: 2.1954 - categorical_accuracy: 0.2119 - val_loss: 2.6598 - val_categorical_accuracy: 0.1684\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 440s 1s/step - loss: 2.1073 - categorical_accuracy: 0.2464 - val_loss: 2.7607 - val_categorical_accuracy: 0.1444\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 438s 1s/step - loss: 2.0693 - categorical_accuracy: 0.2594 - val_loss: 2.7975 - val_categorical_accuracy: 0.2103\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 462s 1s/step - loss: 2.0472 - categorical_accuracy: 0.2663 - val_loss: 2.0981 - val_categorical_accuracy: 0.2668\n",
      "63/63 [==============================] - 45s 722ms/step - loss: 2.2141 - categorical_accuracy: 0.2120\n",
      "True\n",
      "test accuracy:0.21199999749660492\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▄▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▂▁▅█</td></tr><tr><td>val_loss</td><td>▆▇██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>2.09808</td></tr><tr><td>categorical_accuracy</td><td>0.26633</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>2.04721</td></tr><tr><td>test accuracy</td><td>0.212</td></tr><tr><td>val_categorical_accuracy</td><td>0.26683</td></tr><tr><td>val_loss</td><td>2.09808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stoic-sweep-2</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8feinfiv\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8feinfiv</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220329_174749-8feinfiv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u0uhxg0p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: inception_v3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220329_182726-u0uhxg0p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/u0uhxg0p\" target=\"_blank\">jolly-sweep-3</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of bcbd6486424b2319ff4ef7d526e38f63 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 24s 0us/step\n",
      "87924736/87910968 [==============================] - 24s 0us/step\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 674s 2s/step - loss: 1.2810 - categorical_accuracy: 0.6098 - val_loss: 0.8986 - val_categorical_accuracy: 0.7098\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 666s 2s/step - loss: 1.0261 - categorical_accuracy: 0.6792 - val_loss: 0.8553 - val_categorical_accuracy: 0.7267\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 668s 2s/step - loss: 0.9470 - categorical_accuracy: 0.7022 - val_loss: 0.7687 - val_categorical_accuracy: 0.7487\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 663s 2s/step - loss: 0.9012 - categorical_accuracy: 0.7145 - val_loss: 0.7307 - val_categorical_accuracy: 0.7604\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 658s 2s/step - loss: 0.8844 - categorical_accuracy: 0.7254 - val_loss: 0.7215 - val_categorical_accuracy: 0.7624\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 653s 2s/step - loss: 0.8759 - categorical_accuracy: 0.7249 - val_loss: 0.7530 - val_categorical_accuracy: 0.7530\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 663s 2s/step - loss: 0.8382 - categorical_accuracy: 0.7336 - val_loss: 0.7248 - val_categorical_accuracy: 0.7651\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 665s 2s/step - loss: 0.8230 - categorical_accuracy: 0.7338 - val_loss: 0.6739 - val_categorical_accuracy: 0.7741\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 893s 3s/step - loss: 0.8120 - categorical_accuracy: 0.7393 - val_loss: 0.6688 - val_categorical_accuracy: 0.7756\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 2030s 6s/step - loss: 0.7991 - categorical_accuracy: 0.7401 - val_loss: 0.6937 - val_categorical_accuracy: 0.7692\n",
      "63/63 [==============================] - 78s 1s/step - loss: 0.6513 - categorical_accuracy: 0.7930\n",
      "True\n",
      "test accuracy:0.7929999828338623\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▁▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▃▅▆▇▆▇██▇</td></tr><tr><td>val_loss</td><td>█▇▄▃▃▄▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.66882</td></tr><tr><td>categorical_accuracy</td><td>0.74007</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.79915</td></tr><tr><td>test accuracy</td><td>0.793</td></tr><tr><td>val_categorical_accuracy</td><td>0.76918</td></tr><tr><td>val_loss</td><td>0.69366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jolly-sweep-3</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/u0uhxg0p\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/u0uhxg0p</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220329_182726-u0uhxg0p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8kzdmoj9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet_50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220329_204809-8kzdmoj9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8kzdmoj9\" target=\"_blank\">unique-sweep-4</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 1149s 4s/step - loss: 2.3693 - categorical_accuracy: 0.1591 - val_loss: 2.4095 - val_categorical_accuracy: 0.1798\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 4046s 13s/step - loss: 2.2230 - categorical_accuracy: 0.2009 - val_loss: 2.3776 - val_categorical_accuracy: 0.1650\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 982s 3s/step - loss: 2.1620 - categorical_accuracy: 0.2196 - val_loss: 2.3880 - val_categorical_accuracy: 0.1617\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 769s 2s/step - loss: 2.1295 - categorical_accuracy: 0.2351 - val_loss: 2.4924 - val_categorical_accuracy: 0.1880\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 567s 2s/step - loss: 2.1160 - categorical_accuracy: 0.2411 - val_loss: 2.1701 - val_categorical_accuracy: 0.2120\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 544s 2s/step - loss: 2.0934 - categorical_accuracy: 0.2509 - val_loss: 2.4279 - val_categorical_accuracy: 0.1522\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 527s 2s/step - loss: 2.0838 - categorical_accuracy: 0.2524 - val_loss: 2.4817 - val_categorical_accuracy: 0.1872\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 542s 2s/step - loss: 2.0867 - categorical_accuracy: 0.2477 - val_loss: 2.5895 - val_categorical_accuracy: 0.1609\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 521s 2s/step - loss: 2.0725 - categorical_accuracy: 0.2558 - val_loss: 2.2387 - val_categorical_accuracy: 0.2379\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 552s 2s/step - loss: 2.0620 - categorical_accuracy: 0.2608 - val_loss: 2.7037 - val_categorical_accuracy: 0.1371\n",
      "63/63 [==============================] - 46s 740ms/step - loss: 2.6121 - categorical_accuracy: 0.1465\n",
      "True\n",
      "test accuracy:0.14650000631809235\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▃▂▂▁▂▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▄▃▃▅▆▂▄▃█▁</td></tr><tr><td>val_loss</td><td>▄▄▄▅▁▄▅▇▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>2.17008</td></tr><tr><td>categorical_accuracy</td><td>0.26083</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>2.062</td></tr><tr><td>test accuracy</td><td>0.1465</td></tr><tr><td>val_categorical_accuracy</td><td>0.13711</td></tr><tr><td>val_loss</td><td>2.70374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unique-sweep-4</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8kzdmoj9\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/8kzdmoj9</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220329_204809-8kzdmoj9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7a2a8gji with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: inception_v3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220329_234025-7a2a8gji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/7a2a8gji\" target=\"_blank\">blooming-sweep-5</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 458s 1s/step - loss: 1.7243 - categorical_accuracy: 0.5738 - val_loss: 0.6338 - val_categorical_accuracy: 0.8067\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 424s 1s/step - loss: 1.2623 - categorical_accuracy: 0.6833 - val_loss: 0.4938 - val_categorical_accuracy: 0.8439\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 412s 1s/step - loss: 0.9890 - categorical_accuracy: 0.7347 - val_loss: 0.3710 - val_categorical_accuracy: 0.8840\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 414s 1s/step - loss: 0.8271 - categorical_accuracy: 0.7730 - val_loss: 0.3178 - val_categorical_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 440s 1s/step - loss: 0.7350 - categorical_accuracy: 0.7881 - val_loss: 0.2938 - val_categorical_accuracy: 0.9059\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 422s 1s/step - loss: 0.6304 - categorical_accuracy: 0.8167 - val_loss: 0.1804 - val_categorical_accuracy: 0.9391\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 403s 1s/step - loss: 0.5269 - categorical_accuracy: 0.8429 - val_loss: 0.1217 - val_categorical_accuracy: 0.9585\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 453s 1s/step - loss: 0.4581 - categorical_accuracy: 0.8603 - val_loss: 0.0834 - val_categorical_accuracy: 0.9722\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 383s 1s/step - loss: 0.3988 - categorical_accuracy: 0.8755 - val_loss: 0.0758 - val_categorical_accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 414s 1s/step - loss: 0.3597 - categorical_accuracy: 0.8857 - val_loss: 0.0562 - val_categorical_accuracy: 0.9793\n",
      "63/63 [==============================] - 56s 898ms/step - loss: 1.1120 - categorical_accuracy: 0.7850\n",
      "True\n",
      "test accuracy:0.7850000262260437\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▃▅▅▆▆▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▆▄▃▃▂▂▂▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▃▄▅▅▆▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.05616</td></tr><tr><td>categorical_accuracy</td><td>0.88569</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.35969</td></tr><tr><td>test accuracy</td><td>0.785</td></tr><tr><td>val_categorical_accuracy</td><td>0.9793</td></tr><tr><td>val_loss</td><td>0.05616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">blooming-sweep-5</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/7a2a8gji\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/7a2a8gji</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220329_234025-7a2a8gji\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ginxm32b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220330_005256-ginxm32b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/ginxm32b\" target=\"_blank\">leafy-sweep-6</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 462s 1s/step - loss: 0.9784 - categorical_accuracy: 0.7070 - val_loss: 0.4733 - val_categorical_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 432s 1s/step - loss: 0.6070 - categorical_accuracy: 0.8076 - val_loss: 0.3290 - val_categorical_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 437s 1s/step - loss: 0.4701 - categorical_accuracy: 0.8545 - val_loss: 0.2340 - val_categorical_accuracy: 0.9366\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 540s 2s/step - loss: 0.3306 - categorical_accuracy: 0.9012 - val_loss: 0.1497 - val_categorical_accuracy: 0.9682\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 621s 2s/step - loss: 0.2535 - categorical_accuracy: 0.9288 - val_loss: 0.1479 - val_categorical_accuracy: 0.9643\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 566s 2s/step - loss: 0.1955 - categorical_accuracy: 0.9495 - val_loss: 0.0722 - val_categorical_accuracy: 0.9932\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 534s 2s/step - loss: 0.1508 - categorical_accuracy: 0.9653 - val_loss: 0.1126 - val_categorical_accuracy: 0.9689\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 422s 1s/step - loss: 0.1277 - categorical_accuracy: 0.9698 - val_loss: 0.0473 - val_categorical_accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 201s 642ms/step - loss: 0.0986 - categorical_accuracy: 0.9816 - val_loss: 0.0317 - val_categorical_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 200s 640ms/step - loss: 0.0774 - categorical_accuracy: 0.9864 - val_loss: 0.0346 - val_categorical_accuracy: 0.9964\n",
      "63/63 [==============================] - 71s 1s/step - loss: 0.8917 - categorical_accuracy: 0.7735\n",
      "True\n",
      "test accuracy:0.7735000252723694\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▄▅▇▆█▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.03166</td></tr><tr><td>categorical_accuracy</td><td>0.9864</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.07741</td></tr><tr><td>test accuracy</td><td>0.7735</td></tr><tr><td>val_categorical_accuracy</td><td>0.9964</td></tr><tr><td>val_loss</td><td>0.03464</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-sweep-6</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/ginxm32b\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/ginxm32b</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220330_005256-ginxm32b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4t8u0cj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet_50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220330_020919-o4t8u0cj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/o4t8u0cj\" target=\"_blank\">vital-sweep-7</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/lxc7l205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "246/313 [======================>.......] - ETA: 2:25 - loss: 2.5644 - categorical_accuracy: 0.1536"
     ]
    }
   ],
   "source": [
    "do_hyperparameter_search_using_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479da18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
