{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f52d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras.preprocessing.image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467914fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\deep learning project\\inaturalist_12K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,augmentation=True):\n",
    "    train_path=os.path.join(path,\"train\")\n",
    "    test_path=os.path.join(path,\"val\")\n",
    "    if augmentation==False:\n",
    "        train_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.1)\n",
    "    else:\n",
    "        train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90,\n",
    "                                          zoom_range=0.2,\n",
    "                                          shear_range=0.2,\n",
    "                                          validation_split=0.1,\n",
    "                                          horizontal_flip=True)\n",
    "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    train_data = train_generator.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    valid_data=train_generator.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    test_data=test_generator.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "    return train_data,valid_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=256\n",
    "output_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d885e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4005a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "class CNN(object):\n",
    "    def __init__(self,no_conv_layers,kernel_size,learning_rate,epochs,padding,filter_no_metric,dense_layer_size=32,activation_func='relu',\n",
    "               no_filters=32,image_size=256,drop_out=0.2,output_size=10,\n",
    "               augmentation= True,batch_normalization=True):\n",
    "        self.kenel_size=kernel_size\n",
    "        self.learning_rate=learning_rate\n",
    "        self.image_size=image_size\n",
    "        self.output_size=output_size\n",
    "        self.augmentation=augmentation\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.no_conv_layers=no_conv_layers\n",
    "        self.dense_layer_size=dense_layer_size\n",
    "        self.drop_out=drop_out\n",
    "        self.no_filters=no_filters\n",
    "        self.epochs=epochs\n",
    "        self.padding=padding\n",
    "        self.filter_no_metric= filter_no_metric\n",
    "        self.initialize(no_conv_layers,kernel_size,learning_rate,epochs,padding,filter_no_metric,dense_layer_size=32,activation_func='relu',\n",
    "                    no_filters=32,image_size=256,drop_out=0.2,output_size=10,\n",
    "                    augmentation= True,batch_normalization=True)\n",
    "    def initialize(self,no_conv_layers,kernel_size,learning_rate,epochs,padding,filter_no_metric,dense_layer_size=32,activation_func='relu',\n",
    "                 no_filters=32,image_size=256,drop_out=0.2,output_size=10,\n",
    "                    augmentation= True,batch_normalization=True\n",
    "                 ):\n",
    "        self.model=Sequential()\n",
    "        for i in range(0,no_conv_layers):\n",
    "            if i==0:\n",
    "                self.model.add(Conv2D(no_filters,kernel_size, input_shape=(image_size, image_size, 3),kernel_initializer = \"he_uniform\",padding = padding,\n",
    "                           data_format=\"channels_last\"))\n",
    "            else:\n",
    "                if filter_no_metric==\"1\":\n",
    "                    self.model.add(Conv2D(no_filters,kernel_size,kernel_initializer = \"he_uniform\",padding =padding))\n",
    "                elif filter_no_metric==\"2\":\n",
    "                    self.model.add(Conv2D(no_filters*(2**i),kernel_size,kernel_initializer = \"he_uniform\",\n",
    "                                          padding =padding))\n",
    "                elif filter_no_metric==\"1/2\":\n",
    "                    self.model.add(Conv2D(no_filters*(1/(2**i)),kernel_size,kernel_initializer = \"he_uniform\",\n",
    "                                          padding =padding))\n",
    "\n",
    "            self.model.add(Activation(activation_func))\n",
    "            if batch_normalization==True:\n",
    "                self.model.add(BatchNormalization())\n",
    "            self.model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_layer_size))\n",
    "        self.model.add(Activation(activation_func))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "np.random.seed(2)\n",
    "class Runner(object):\n",
    "    def __init__(self,inaturalist_data=True,augmentation=True):\n",
    "        if inaturalist_data:\n",
    "            self.initialize_inaturalist_data(augmentation)\n",
    "        else:\n",
    "            self.initialize_data()\n",
    "\n",
    "    def initialize_inaturalist_data(self,augmentation=True):\n",
    "        self.train_data,self.valid_data,self.test_data= get_data(path,augmentation)\n",
    "    \n",
    "\n",
    "    def initialize_data(self):\n",
    "        raise NotImplementedError(\"Please implement this method if you need other dataset.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_activation_function(key):\n",
    "        mapper = {\n",
    "      #\"sigmoid\": Sigmoid,\n",
    "      \"relu\": 'relu'\n",
    "      #\"tanh\": Tanh\n",
    "    }\n",
    "        assert key in mapper\n",
    "        return mapper[key]\n",
    "\n",
    "def run_wandb():\n",
    "    wandb.init(project=\"bayesian\", entity=\"cs21m003_cs21d406\")\n",
    "    config = wandb.config\n",
    "    wandb.run.name=f\"e_{config.epochs}_bs_{config.batch_size}_kernel_size_{config.kernel_size}_filters_{config.no_filters}_ac_{config.act_func}_rate_{config.learning_rate}_aug_{config.augmentation}_BN_{config.batch_normalization}_drp_{config.drop_out}_pad_{config.padding}_dense_{config.dense_size}_metric_{config.filter_no_metric}_type_{config.type}\"\n",
    "    runner=Runner(True,config.augmentation)\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    \"epochs\"        : config.epochs,\n",
    "    \"batch_size\"    : config.batch_size,\n",
    "    \"kernel_size\"   : config.kernel_size,\n",
    "    \"no_filters\"    : config.no_filters,\n",
    "    \"act_func\"      : config.act_func,\n",
    "    \"learning_rate\" : config.learning_rate,\n",
    "    \"augmentation\"  : config.augmentation,\n",
    "    \"batch_normalization\"  : config.batch_normalization,\n",
    "    \"drop_out\"  : config.drop_out,\n",
    "    \"padding\": config.padding,\n",
    "    \"dense_size\":config.dense_size,\n",
    "    \"filter_no_metric\":config.filter_no_metric\n",
    "\n",
    "    }\n",
    "    \"\"\"\n",
    "  #no_conv_layers,filter_size,learning_rate,epochs,padding,filter_size_metric,dense_layer_size=32,activation_func='relu',\n",
    "              # no_filters=32,image_size=256,drop_out=0.2,output_size=10,\n",
    "               #augmentation= True,batch_normalization=True)\n",
    "    model_1=CNN(5,config.kernel_size,config.learning_rate,config.epochs,config.padding,config.filter_no_metric,config.dense_size,config.act_func,\n",
    "              config.no_filters,image_size,config.drop_out,output_size,config.augmentation,config.batch_normalization)\n",
    "    model_1.model.compile(\n",
    "    optimizer=Adam(config.learning_rate),  # Optimizer\n",
    "    loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
    "  #train_data,valid_data,test_data=get_data(path,augmentation=True)\n",
    "    model_1.model.fit(runner.train_data,epochs=config.epochs,batch_size=config.batch_size,validation_data=runner.valid_data,\n",
    "          callbacks=[WandbCallback()])\n",
    "    loss,accuracy=model_1.model.evaluate(runner.test_data,batch_size=config.batch_size)\n",
    "    print(f'test accuracy:{accuracy}')\n",
    "    wandb.log({\"test accuracy\":accuracy})\n",
    "\n",
    "def do_hyperparameter_search_using_wandb():\n",
    "    sweep_config = {\n",
    "    \"name\": \"bayesian sweep\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\":{\n",
    "      \"name\": \"ValidationAccuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "      \"type\": {\"values\": ['bayesian']},\n",
    "      \"epochs\": {\"values\": [5, 10]}, \n",
    "      \"batch_size\": {\"values\": [ 64]}, \n",
    "      \"kernel_size\": {\"values\": [(4,4), (5,5)]}, \n",
    "      \"no_filters\": {\"values\": [32,64,128]},\n",
    "      \"act_func\": {\"values\": ['elu', 'relu', 'selu']}, \n",
    "      \"learning_rate\": {\"values\": [1e-3, 1e-4]}, \n",
    "      \"augmentation\": {\"values\": [True,False]} , \n",
    "      \"batch_normalization\": {\"values\": [True,False]},\n",
    "      \"drop_out\": {\"values\": [0.5]},\n",
    "      \"padding\": {\"values\": ['same','valid']},\n",
    "      \"dense_size\": {\"values\": [64,128]},\n",
    "      \"filter_no_metric\": {\"values\": [\"1\",\"2\",\"1/2\"]}}}\n",
    "  \n",
    "    sweep_id = wandb.sweep(sweep_config, project = \"bayesian\",entity='cs21m003_cs21d406')\n",
    "    wandb.agent(sweep_id, function=run_wandb,count=20)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    do_hyperparameter_search_using_wandb() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab9844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
