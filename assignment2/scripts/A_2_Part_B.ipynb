{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ff3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras import  models, optimizers, layers, activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5076437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D ,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f3bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6958962659163926141\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2258055988\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9602183712390426133\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd46403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\deep_learning_project\\inaturalist_12K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b824eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(256,256,3)\n",
    "output_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae69b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,augmentation=True):\n",
    "    train_path=os.path.join(path,\"train\")\n",
    "    test_path=os.path.join(path,\"val\")\n",
    "    if augmentation==False:\n",
    "        train_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.1)\n",
    "    else:\n",
    "        train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90,\n",
    "                                          zoom_range=0.2,\n",
    "                                          shear_range=0.2,\n",
    "                                          validation_split=0.1,\n",
    "                                          horizontal_flip=True)\n",
    "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    train_data = train_generator.flow_from_directory(\n",
    "                                                        directory=train_path,\n",
    "                                                        target_size=(256, 256),\n",
    "                                                        color_mode=\"rgb\",\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=42)\n",
    "    valid_data=train_generator.flow_from_directory(\n",
    "                                                        directory=train_path,\n",
    "                                                        target_size=(256, 256),\n",
    "                                                        color_mode=\"rgb\",\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=42)\n",
    "    test_data=test_generator.flow_from_directory(\n",
    "                                                        directory=test_path,\n",
    "                                                        target_size=(256, 256),\n",
    "                                                        color_mode=\"rgb\",\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=42)\n",
    "    return train_data,valid_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f3f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0e0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inc_v2(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=InceptionResNetV2(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size,\n",
    "        )\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd98131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inc_v3(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=InceptionV3(include_top=False,\n",
    "            weights=\"imagenet\", \n",
    "            input_shape=input_size,\n",
    "        )\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c12124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xcpt_ion(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=Xception(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size)\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c645fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_net(object):\n",
    "    def __init__(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.input_size =input_size\n",
    "        self.output_size=output_size\n",
    "        self.drop_out=drop_out\n",
    "        self.batch_normalization=batch_normalization\n",
    "        self.initialize(input_size,output_size,drop_out,batch_normalization,dense_size)\n",
    "    def initialize(self,input_size,output_size,drop_out,batch_normalization,dense_size):\n",
    "        self.model_b=ResNet50(include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=input_size)\n",
    "        self.model_b.trainable=False\n",
    "        input = keras.Input(shape=input_size)\n",
    "        x = self.model_b(input, training=False)\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Model(input, x))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(dense_size))\n",
    "        self.model.add(Activation('selu'))\n",
    "        if batch_normalization==True:\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(drop_out))\n",
    "        self.model.add(Dense(output_size))\n",
    "        self.model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101a3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4194336   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 27,782,506\n",
      "Trainable params: 4,194,730\n",
      "Non-trainable params: 23,587,776\n",
      "_________________________________________________________________\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "model=Res_net(image_size,output_size,0.4,True,32)\n",
    "model.model.summary()\n",
    "\n",
    "print(model.model_b.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1678d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models={\"inception_v2\":inc_v2,\"inception_v3\":inc_v3,\"Xception\":Xcpt_ion,\"Resnet_50\":Res_net}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141d4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makashsainics21m003\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519208ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663ba1b",
   "metadata": {},
   "source": [
    "# FINETUNING PRETRAINED MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8b904e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "np.random.seed(2)\n",
    "class Runner(object):\n",
    "    def __init__(self,inaturalist_data=True,augmentation=True):\n",
    "        if inaturalist_data:\n",
    "            self.initialize_inaturalist_data(augmentation)\n",
    "        else:\n",
    "            self.initialize_data()\n",
    "\n",
    "    def initialize_inaturalist_data(self,augmentation=True):\n",
    "        self.train_data,self.valid_data,self.test_data= get_data(path,augmentation)\n",
    "    \n",
    "\n",
    "    def initialize_data(self):\n",
    "        raise NotImplementedError(\"Please implement this method if you need other dataset.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_activation_function(key):\n",
    "        mapper = {\n",
    "      #\"sigmoid\": Sigmoid,\n",
    "      \"relu\": 'relu'\n",
    "      #\"tanh\": Tanh\n",
    "    }\n",
    "        assert key in mapper\n",
    "        return mapper[key]\n",
    "\n",
    "def run_wandb():\n",
    "    wandb.init(project=\"pretrained_model\", entity=\"cs21m003_cs21d406\")\n",
    "    config = wandb.config\n",
    "    base_model=trained_models[config.models]\n",
    "    wandb.run.name=f\"model_{config.models}_e_{config.epochs}_bs_{config.batch_size}_rate_{config.learning_rate}_aug_{config.augmentation}_BN_{config.batch_normalization}_drp_{config.drop_out}_dense_{config.dense_size}\"\n",
    "    runner=Runner(True,config.augmentation)\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    \"epochs\"        : config.epochs,\n",
    "    \"batch_size\"    : config.batch_size,\n",
    "    \"act_func\"      : config.act_func,\n",
    "    \"learning_rate\" : config.learning_rate,\n",
    "    \"augmentation\"  : config.augmentation,\n",
    "    \"batch_normalization\"  : config.batch_normalization,\n",
    "    \"drop_out\"  : config.drop_out,\n",
    "    \"dense_size\":config.dense_size,\n",
    "    \"models\": config.models\n",
    "\n",
    "    }\n",
    "    \"\"\"\n",
    "    model_1=base_model(image_size,output_size,config.drop_out,config.batch_normalization,config.dense_size)\n",
    "    model_1.model.compile(\n",
    "    optimizer=Adam(config.learning_rate),  # Optimizer\n",
    "    loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
    "    model_1.model.fit(runner.train_data,epochs=config.epochs,batch_size=config.batch_size,validation_data=runner.valid_data,\n",
    "          callbacks=[WandbCallback()])\n",
    "    loss,accuracy=model_1.model.evaluate(runner.test_data,batch_size=config.batch_size)\n",
    "    model_1.model_b.trainable=True\n",
    "    print(model_1.model_b.trainable)\n",
    "    print(f'test accuracy:{accuracy}')\n",
    "    wandb.log({\"test accuracy\":accuracy})\n",
    "\n",
    "def do_hyperparameter_search_using_wandb():\n",
    "    sweep_config = {\n",
    "    \"name\": \"random sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\":{\n",
    "      \"name\": \"ValidationAccuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "      \"epochs\": {\"values\": [5,10]}, \n",
    "      \"batch_size\": {\"values\": [64]}, \n",
    "      #\"act_func\": {\"values\": ['elu', 'relu', 'selu']}, \n",
    "      \"learning_rate\": {\"values\": [1e-3, 1e-4]}, \n",
    "      \"augmentation\": {\"values\": [True,False]} , \n",
    "      \"batch_normalization\": {\"values\": [True,False]},\n",
    "        \n",
    "      \"drop_out\": {\"values\": [0.3,0.4,0.5]},\n",
    "      \"models\": {\"values\": [\"inception_v2\"]},\n",
    "      \"dense_size\": {\"values\": [32,64]}}}\n",
    "  \n",
    "    sweep_id = wandb.sweep(sweep_config, project = \"pretrained_model\",entity='cs21m003_cs21d406')\n",
    "    wandb.agent(sweep_id, function=run_wandb,count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5982be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 966enmsy\n",
      "Sweep URL: https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/966enmsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9nay3qo7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: inception_v2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220401_081513-9nay3qo7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/9nay3qo7\" target=\"_blank\">fanciful-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/966enmsy\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/966enmsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 589s 2s/step - loss: 3.3309 - categorical_accuracy: 0.2149 - val_loss: 1.8364 - val_categorical_accuracy: 0.3243\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 448s 1s/step - loss: 2.5998 - categorical_accuracy: 0.2395 - val_loss: 1.6901 - val_categorical_accuracy: 0.3800\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 446s 1s/step - loss: 2.1716 - categorical_accuracy: 0.2657 - val_loss: 1.5865 - val_categorical_accuracy: 0.4088\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 438s 1s/step - loss: 1.9565 - categorical_accuracy: 0.2893 - val_loss: 1.4933 - val_categorical_accuracy: 0.4464\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 429s 1s/step - loss: 1.8131 - categorical_accuracy: 0.3229 - val_loss: 1.3735 - val_categorical_accuracy: 0.4639\n",
      "63/63 [==============================] - 57s 900ms/step - loss: 1.4421 - categorical_accuracy: 0.4550\n",
      "True\n",
      "test accuracy:0.45500001311302185\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▃▄▆█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▅▃▂▁</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▄▅▇█</td></tr><tr><td>val_loss</td><td>█▆▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>1.37347</td></tr><tr><td>categorical_accuracy</td><td>0.32293</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>1.81315</td></tr><tr><td>test accuracy</td><td>0.455</td></tr><tr><td>val_categorical_accuracy</td><td>0.46395</td></tr><tr><td>val_loss</td><td>1.37347</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-sweep-1</strong>: <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/9nay3qo7\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/9nay3qo7</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220401_081513-9nay3qo7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1omo9inq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: inception_v2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\akash saini\\wandb\\run-20220401_085745-1omo9inq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/runs/1omo9inq\" target=\"_blank\">winter-sweep-2</a></strong> to <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/966enmsy\" target=\"_blank\">https://wandb.ai/cs21m003_cs21d406/pretrained_model/sweeps/966enmsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 477s 1s/step - loss: 1.3611 - categorical_accuracy: 0.6723 - val_loss: 0.5645 - val_categorical_accuracy: 0.8234\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 463s 1s/step - loss: 0.9679 - categorical_accuracy: 0.7502 - val_loss: 0.4303 - val_categorical_accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 476s 2s/step - loss: 0.7711 - categorical_accuracy: 0.7934 - val_loss: 0.3350 - val_categorical_accuracy: 0.8880\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 388s 1s/step - loss: 0.6219 - categorical_accuracy: 0.8232 - val_loss: 0.2305 - val_categorical_accuracy: 0.9209\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 383s 1s/step - loss: 0.5026 - categorical_accuracy: 0.8575 - val_loss: 0.1920 - val_categorical_accuracy: 0.9320\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 412s 1s/step - loss: 0.4334 - categorical_accuracy: 0.8692 - val_loss: 0.1645 - val_categorical_accuracy: 0.9412\n",
      "Epoch 7/10\n",
      " 43/313 [===>..........................] - ETA: 2:24 - loss: 0.3803 - categorical_accuracy: 0.8844"
     ]
    }
   ],
   "source": [
    "do_hyperparameter_search_using_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479da18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
